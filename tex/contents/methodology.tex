\chapter{Methodology}
\label{methodology}

\section{Requirements}
\label{methodology:s:requirements}

\subsection{Current Architecture}
\label{methodology:ss:current-architecture}

The current software architecture is still in use as of the date of publication of this body of work. This older architecture consists of an amalgamation of Docker containers, each running a different service. Each Client has its own \gls{vps} wherein these Docker containers are deployed. 

\subsubsection{\gls{vpc}}
\label{methodology:sss:vpc}

These \gls{vps} are general-purpose \gls{aws} \gls{ec2} \textit{Instances}. As can be seen on the diagram presented on \Cref{fig:old-arch-overview}, these instances are deployed to the same \gls{vpc}, sharing a private network between them. The Reverse Proxy serves as, as the name implies, as a reverse proxy to enable the use of a single \gls{eip}, a single \gls{eni} by all Clients's servers, since the availability of public IPs is limited to five \gls{eip}.
\input{tex/contents/fig/old-arch-overview.drawio.pdf.tex}

\subsubsection{\gls{vpc}}
\label{methodology:sss:vpc}

Each \gls{ec2} instance runs a Docker container for each one of the following services:

\begin{itemize}

\item \textbf{InfluxDB} (Timeseries Database)
\item \textbf{MongoDB} (General use, no-SQL, Document Database)
\item \textbf{Grafana} (Web platform for data visualization, the front end of the \gls{dss})
\item \textbf{Telegraf} (Data collecting service)
\item \textbf{Nginx} (Reverse proxy with \gls{https} capabilities)
\item \textbf{Let's Encrypt} (Automatic \gls{tls} Certificate installer, companion for the Nginx container)
\item \textbf{Web Dev} (Web platform / API for managing Workers' settings)
\item \textbf{Redis} (Message Queue System for queuing Worker's jobs)
\item \textbf{OpenSSH} (\textit{atmoz/sftp}) (\gls{ssh} Server for receiving client data through \gls{sftp})
\item \textbf{Workers} (Container running the Forecast, Simulation and Optimization Python Algorithms as well as the \gls{kpi} Algorithms.)
\item \textbf{Workers} (\textit{Beat}) (Container that periodically \textit{triggers} jobs in the Workers container)

\end{itemize}

\input{tex/contents/fig/old-arch.drawio.pdf.tex}


\subsubsection{Databases}
\label{methodology:sss:databases}

There are two types of databases being used by this architecture: A Timeseries Database, in this case \textbf{InfluxDB}, and an additional general-purpose Document Database: \textbf{MongoDB}. Each type of database has a different role, the first one stores the Client's timeseries data such as sensor information, pump orders, predicted tank levels, etc.
The second one, the Document Database, is responsible for storing configuration settings for each worker service (optimization, simulation and forecasting), for storing electrical tariffs data and to store sensor device's configurations.

\subsubsection{Grafana}
\label{methodology:sss:grafana}

This web platform allows the visualization of the Timeseries data from the \textbf{InfluxDB} database. This is a freely-available platform that runs on a docker container with little to no modifications necessary. The dashboards are built using the built-in tools and allow for complex and very informative data visualization. This is used in both the new and old architecture, since the new visualization platform is still not operational (not within the scope of this body of work).

\subsubsection{Telegraf}
\label{methodology:sss:telegraf}

The \textbf{Telegraf} container is used to gather the files containing the raw sensor data sent from the Client to the \gls{sftp} server. Since this container shares the file upload location folder with the \gls{sftp}, through a convoluted process of storing the filename of the last file uploaded, periodically checking for the next file and file handling \textit{spaghetti} code that spans multiple files and has an enormous codebase that weighs the docker image's file size considerably. 

\subsubsection{\gls{sftp}}
\label{methodology:sss:sftp}

The \gls{sftp} service here provides a secure method for the Clients to send files containing the Timeseries data to our servers, where they can be processed and turned into actionable insights by the algorithms running in the Workers container. The Client sends their public key (from a cryptographic key pair) when the project start to authenticate against this \gls{sftp} service and uploads the files to a pre-designated folder. These files are then accessed by the Telegraf container which does the file intake.


\subsubsection{Nginx + Let's Encrypt}
\label{methodology:sss:nginxletsencrypt}

These two containers allow secure Internet access from the \gls{ec2} instance into the correct docker container IP address and port. The Client-facing services Grafana and \gls{sftp} which, respectively, provide the web interface for the \gls{dss} and client file input service are inside containers which themselves can change their internal IP inside the Docker environment. To keep the dynamic IPs in check and allow for these services to be accessed from outside the Docker environment the Nginx container keeps track of this dynamic IP and updates its route table accordingly. This allows for any of these two containers to restart, change their IP address and still not break the routing back to the host \gls{ec2} instance, which has an \gls{eni} associated to it exclusively. This \gls{eni} is then connected, exclusively, to a single \gls{eip} to which the Clients connect, like \Cref{fig:old-arch-nginx} implies.

As for the Let's Encrypt container, this container shares a docker volume with the Nginx container and automatically and periodically maintains the \gls{tls} certificate files that the Nginx requires in order to serve the Grafana interface through \gls{https}. 
\input{tex/contents/fig/old-arch-nginx.drawio.pdf.tex}

\subsubsection{Redis}
\label{methodology:sss:redis}

We use Redis \parencite{redis_2022} as a message queue backend for Celery \parencite{celery}, enabling other services to send Celery tasks to a queue for asynchronous execution by the Workers.

\subsubsection{Web Dev}
\label{methodology:sss:webdev}

This is an \gls{api}, which also serves a web page, that gives developers access to algorithm configurations and the ability to push Celery tasks to the queue. 

\subsubsection{Workers}
\label{methodology:sss:workers}

This is where the \textit{magic} happens. The Workers' container image is built \textit{in-house} by the development team, using a \textit{Python} Docker image as the base image, wherein all the company's algorithms lay. The \textit{forecast}, \textit{optimization} and \textit{performance analysis}/\gls{kpi} algorithms are individually linked in a Celery configuration file, which defines how each algorithm is executed in a Celery task and how that task is called. This container executes a Celery Worker that executes all Celery Tasks in the Celery task queue.

When a task is sent to the task queue, this Celery Worker who polls the task queue, picks the task up and starts executing the task as soon as possible.

There are two Workers images, the first one contains the code for all algorithms and is the one which starts the Celery worker. The other one, which is internally called Celery Beat, executes a Celery instance in \textit{Beat} mode which sends pre-configured Celery tasks to the queue. This is used to run the algorithms periodically in order to process the Client data and generate actionable insights for the Client.

These algorithms require decent amounts of computer resources, namely CPU power and RAM capacity, in order to be able to run effectively. This is a direct contrast to the remaining components of this old architecture, which see minimal Client use and are therefore less resource intensive. In terms of storage, the situation is the opposite since these algorithms use data stored within the other services - the database services.

\section{Issues}
\label{methodology:s:issues}

\subsection{Resource Sizing}
\label{methodology:ss:resource sizing}

\input{tex/contents/fig/caesb-cpu-usage.tex}

The contrast between the different services' computational and storage requirements is one of the major issues with the old architecture. Adequate instance sizing is essential to lower infrastructure costs with compute resources. As can be seen in \Cref{fig:caesb-cpu-usage}, the CPU average utilization is usually very low, indicating that the resources allocated to this instance are way overestimated, elevating the infrastructure costs for no reason. However, the peaks in CPU usage that can be observed in this same Figure, which are caused by the periodically-running algorithms, push this CPU usage up to levels that suggest the allocated resources are somewhat adequate for this use-case. And wherein lies one of the major issues: over a 24-hour period, the amount of time spent with very low CPU usage is visibly and significantly superior to the time spent with adequate CPU usage for the instance size. 

The \gls{ec2} instance upon which these services reside can be provisioned and sized to different computational and storage needs. However, this would mean that it would either be adequately sized for the times the workers are dormant and undersized for when the algorithms are running, or oversized for most of the time and only adequately sized while running said algorithms. Unfortunately, resizing an \gls{ec2} instance requires downtime for the whole platform, since it requires the \gls{ec2} instance to be rebooted. Since this would also stop Client access to the \gls{dss} and data intake service, this option cannot be contemplated. After testing a platform implementation with an instance adequately sized for when the workers are dormant, the development team came to the conclusion that the algorithms would either refuse to run or crash when performing resource intensive calculations due to low RAM availability. The decision was then made, to keep the platform running in oversized, and costly, \gls{ec2} instances.

Therefore, one of the goals of this work is to attempt to solve this problem. One of the possible general solutions was to split the resources based on their compute resource requirements. Having the workers on a separate \gls{ec2} instance that would be automatically and periodically provisioned and unprovisioned according to a schedule would allow the remaining services to be placed in a lower cost \gls{ec2} instance, lowering the overall infrastructure costs. However, without altering the existing architecture, this would mean that the alteration would only be the place where the Workers' docker container would be executed. Since the amount of \gls{ec2} instances is directly proportional to the amount of Clients, having two instances would duplicate the computational resources, networks connections and storage space needed to maintain the platform for all Clients. This would exacerbate the problem of limited compute resources available to our \gls{aws} account.

\subsection{Limited Compute Resources}
\label{methodology:ss:limited-compute-resources}

One of the issues with the old architecture is that the number of \gls{ec2} instances needed was directly tied to the amount of Clients, since each Client required its own instance to host the platform, generating what is called a Scalability problem. For the company's \gls{aws} account, a limit of thirty-two (32) \gls{vcpu} units (each \gls{vcpu} corresponds to a processing thread in a CPU core) was imposed by Amazon as default, which meant that the sum of \gls{ec2} instance's \gls{vcpu} units could not surpass this value. Each client requires an \gls{ec2} instance of the type \textit{t3a.large} or \textit{t3a.xlarge}, respectively two (2) or four (4) \gls{vcpu} units, depending on the Client's Water Network's size and complexity and contracted services. This would mean that the amount of clients was limited from sixteen (16) clients if they all used the smaller instance or down to eight (8) clients if these Clients required more resources. As can be concluded this is a hard limit on the amount of clients that can be served simultaneously by the company, which is obviously a problem.
